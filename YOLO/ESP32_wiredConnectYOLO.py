# æ‰¾åˆ°bounding boxä¸­å¿ƒé»è·Ÿé›·å°„å…‰é»çš„ä½ç½®ï¼Œä»¥æ¯å€‹ä¸­å¿ƒé»ç‚ºä¸­å¿ƒç®—å‡ºé›·å°„å…‰ä½ç½®ï¼Œä¸¦å­˜æˆjsonæª”
import cv2, time, os, json
from collections import deque
import threading
import queue
from ultralytics import YOLO
import numpy as np
import serial
import serial.tools.list_ports


model = YOLO("best.pt")

# ====== åƒæ•¸ ======
BUFFER_SIZE = 20           # ä¿ç•™æœ€è¿‘20å¹€
PRE_FRAMES = 3             # å–æŒ‰ä¸‹å‰3å¹€
POST_FRAMES = 5            # å–æŒ‰ä¸‹å¾Œ5å¹€ï¼ˆè¦é ä¸€é»å»¶é²ç­‰åˆ°å¹€é€²ä¾†ï¼‰
POST_WAIT_SEC = 0.12       # ç­‰å¾…å¾ŒçºŒå¹€é€²bufferçš„æ™‚é–“ï¼ˆä¾FPSèª¿ï¼‰

USER_ID = "user_001"
MAX_SHOTS = 5
SAVE_DIR = "shots_json"
SAVE_FRAMES_DIR = "shots_frames"  # å„²å­˜è™•ç†å¹€çš„è³‡æ–™å¤¾
CONF_THRES = 0.8          # YOLO åµæ¸¬ä¿¡å¿ƒåº¦é–¾å€¼
DEBOUNCE_SEC = 0.25          # å»æŠ–å‹•:è‡³å°‘éš”é€™éº¼ä¹…æ‰ç®—ä¸‹ä¸€ç™¼(é¿å…åŒä¸€ç™¼é€£çºŒå¹€é‡è¤‡å¯«)
os.makedirs(SAVE_DIR, exist_ok=True)
os.makedirs(SAVE_FRAMES_DIR, exist_ok=True)

# ====== å…±äº«è³‡æ–™ ======
frame_buffer = deque(maxlen=BUFFER_SIZE)  # æ¯ç­†: (ts, frame)
fire_events = queue.Queue()               # å­˜ "fire timestamp"
stop_flag = False

def atomic_write_json(path, data):
    tmp = path + ".tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    os.replace(tmp, path)

# ====== ä½ çš„åµæ¸¬ï¼šè«‹æ¥ä½ ç¾æœ‰çš„ yolo_detect + select_best_hit_candidate ======
def yolo_detect(frame):
    results = model.predict(source=frame, save=False, verbose=False)  # ä¸å„²å­˜ï¼Œæ¸›å°‘è¼¸å‡º
    return results
def detect_point_in_roi(roi_image, offset_x, offset_y):

    """åœ¨æŒ‡å®šçš„ ROI å€åŸŸå…§åµæ¸¬ç´…è‰²å…‰é»ï¼Œå›å‚³çµ•å°åº§æ¨™çš„bbox list: [(x,y,w,h), ...]"""
    point_boxes = []
    hsv = cv2.cvtColor(roi_image, cv2.COLOR_BGR2HSV)

    # ç´…è‰²åœ¨HSVè‰²ç›¸ç’°çš„å…©ç«¯ï¼Œéœ€è¦å…©å€‹ç¯„åœ
    lower_red1 = np.array([0, 0, 150])
    upper_red1 = np.array([15, 255, 255])
    lower_red2 = np.array([165, 0, 150])
    upper_red2 = np.array([180, 255, 255])

    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask = cv2.bitwise_or(mask1, mask2)

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    for c in contours:
        if cv2.contourArea(c) > 30 :  # é–¾å€¼
            x, y, w, h = cv2.boundingRect(c)
            point_boxes.append((x + offset_x, y + offset_y, w, h))

    return point_boxes

def bbox_center_xyxy(x1, y1, x2, y2):
    return ((x1 + x2) / 2.0, (y1 + y2) / 2.0)

def bbox_center_xywh(x, y, w, h):
    return (x + w / 2.0, y + h / 2.0)
def select_best_hit_candidate(frame, yolo_results):
    """
    å¾æ‰€æœ‰YOLOæ¡†ä¸­æ‰¾å‡ºã€Œæ¡†å…§æœ‰ç¶ é»ã€çš„å€™é¸ï¼Œ
    ä¸¦æŒ‘é¸ conf æœ€é«˜çš„ä¸€å€‹ä½œç‚ºæœ¬æ¬¡æ“Šä¸­ç›®æ¨™ã€‚
    åŒæ™‚è¨ˆç®—è©²ç›®æ¨™å¾å·¦åˆ°å³æ˜¯ç¬¬å¹¾å€‹ï¼ˆæœ€å·¦é‚Šæ˜¯1ï¼‰
    å›å‚³ dict æˆ– None
    """
    h_img, w_img = frame.shape[:2]
    
    # å…ˆæ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„ç›®æ¨™æ¡†ï¼ˆç”¨æ–¼æ’åºç·¨è™Ÿï¼‰
    all_targets = []
    candidates = []
    
    for r in yolo_results:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            cls = int(box.cls[0])
            conf = float(box.conf[0])

            if conf < CONF_THRES:
                continue

            # clamp
            x1 = max(0, x1); y1 = max(0, y1)
            x2 = min(w_img, x2); y2 = min(h_img, y2)
            if x2 <= x1 or y2 <= y1:
                continue

            # è¨ˆç®—ä¸­å¿ƒé» x åº§æ¨™ç”¨æ–¼æ’åº
            center_x = (x1 + x2) / 2.0
            all_targets.append({
                "center_x": center_x,
                "x1": x1, "y1": y1, "x2": x2, "y2": y2,
                "cls": cls, "conf": conf
            })

    # æŒ‰ç…§ center_x å¾å·¦åˆ°å³æ’åºï¼Œå»ºç«‹ç·¨è™Ÿ
    all_targets.sort(key=lambda t: t["center_x"])
    # target_numbers = {t["center_x"]: idx + 1 for idx, t in enumerate(all_targets)}
    for idx, t in enumerate(all_targets):
        t["No"] = idx

    # ç¾åœ¨æª¢æŸ¥æ¯å€‹ç›®æ¨™æ˜¯å¦æœ‰ç¶ é»
    for target in all_targets:
        x1, y1, x2, y2 = target["x1"], target["y1"], target["x2"], target["y2"]
        cls = target["cls"]
        conf = target["conf"]
        center_x = target["center_x"]
        
        roi = frame[y1:y2, x1:x2]
        if roi.size == 0:
            continue

        # åœ¨é€™å€‹æ¡†å…§åµæ¸¬ç¶ é»
        point_boxes = detect_point_in_roi(roi, x1, y1)
        if len(point_boxes) == 0:
            continue

        # å¤šå€‹ç¶ é»æ™‚ï¼šå–é¢ç©æœ€å¤§çš„é‚£å€‹ï¼ˆé€šå¸¸æ¯”è¼ƒç©©ï¼‰
        def area(pb): 
            _, _, pw, ph = pb
            return pw * ph
        px, py, pw, ph = max(point_boxes, key=area)
        green_area = pw * ph

        target_cx, target_cy = bbox_center_xyxy(x1, y1, x2, y2)
        laser_cx, laser_cy = bbox_center_xywh(px, py, pw, ph)

        # è¨ˆç®—åƒç´ å·®å€¼
        dx_px = laser_cx - target_cx
        dy_px = laser_cy - target_cy
        
        # è¨ˆç®—æ¨™é¶çš„å¯¬é«˜
        target_width = x2 - x1
        target_height = y2 - y1
        
        # è½‰æ›ç‚ºæ­¸ä¸€åŒ–åº§æ¨™: ä¸­å¿ƒç‚º(0,0)ï¼Œå·¦ä¸Š(-0.5,-0.5)ï¼Œå³ä¸‹(0.5,0.5)
        # Xè»¸: å‘å³ç‚ºæ­£
        # Yè»¸: å‘ä¸‹ç‚ºæ­£ (èˆ‡åœ–åƒåº§æ¨™ç³»çµ±ä¸€è‡´)
        dx_normalized = (dx_px / target_width)
        dy_normalized = (dy_px / target_height)  # å‘ä¸‹ç‚ºæ­£
        
        # è¨ˆç®—é»è½åœ¨å“ªå€‹æ©¢åœ“å€åŸŸ
        # ä½¿ç”¨æ©¢åœ“è·é›¢å…¬å¼: sqrt((x/a)^2 + (y/b)^2)
        # å…¶ä¸­ a, b æ˜¯æ©¢åœ“çš„åŠè»¸é•·åº¦,é€™è£¡éƒ½æ˜¯ 1.0 (å› ç‚ºå·²æ­¸ä¸€åŒ–)
        distance_normalized = np.sqrt(dx_normalized**2 + dy_normalized**2)
        
        # å°‡æ¨™é¶åˆ†æˆ5å€‹åŒå¿ƒæ©¢åœ“è¨ˆåˆ†: 10, 9, 8, 7, 6
        # æ¯å±¤æ©¢åœ“ç¯„åœ: 0.5 / 5 = 0.1
        # ä¾‹å¦‚: é»åœ¨ (0.3, 0.1) â†’ sqrt(0.3^2 + 0.1^2) = 0.316 â†’ 8åˆ†å€
        if distance_normalized <= 0.1:
            score = 10  
        elif distance_normalized <= 0.2:
            score = 9   
        elif distance_normalized <= 0.3:
            score = 8   
        elif distance_normalized <= 0.4:
            score = 7   
        else:
            score = 6
        
        candidate = {
            # "No": target_numbers[center_x],  # å¾å·¦åˆ°å³çš„ç·¨è™Ÿ
            "No": target["No"],
            "cls": cls,
            "conf": conf,
            "target_center": (target_cx, target_cy), # çœŸæ­£ä¸­å¿ƒåº§æ¨™
            "laser_center": (laser_cx, laser_cy),
            "dx": dx_normalized,  # æ­¸ä¸€åŒ–åº§æ¨™
            "dy": dy_normalized,  # æ­¸ä¸€åŒ–åº§æ¨™
            "dx_px": dx_px,  # ä¿ç•™åƒç´ å€¼ä¾›debug
            "dy_px": dy_px,
            "distance": distance_normalized,  # è·é›¢ä¸­å¿ƒçš„æ­¸ä¸€åŒ–è·é›¢
            "score": score,  # ç’°ç‹€è¨ˆåˆ†
            "green_area": green_area  # ç¶ é»é¢ç©
        }
        
        candidates.append(candidate)
    
    if not candidates: # å®Œå…¨æ²’åµæ¸¬åˆ°ç¶ é»
        return None
    
    # å¾æ‰€æœ‰å€™é¸ä¸­é¸æ“‡ç¶ é»é¢ç©æœ€å¤§çš„ï¼ˆæœ€æ˜é¡¯çš„æ“Šä¸­ï¼‰
    best = max(candidates, key=lambda c: c["green_area"])
    return best

def detect_from_frames(frames, shot_idx):
    """
    frames: list of (ts, frame)
    å›å‚³ best_payloadï¼ˆå‘½ä¸­ï¼‰æˆ– miss_payloadï¼ˆæ²’å‘½ä¸­ï¼‰
    åŒæ™‚å°‡æ‰€æœ‰è™•ç†çš„å¹€å­˜æˆåœ–ç‰‡
    """
    best = None
    best_ts = None
    best_frame_idx = None

    # å»ºç«‹æ­¤æ¬¡shotçš„è³‡æ–™å¤¾
    shot_dir = os.path.join(SAVE_FRAMES_DIR, f"shot{shot_idx:02d}")
    os.makedirs(shot_dir, exist_ok=True)

    for idx, (ts, frame) in enumerate(frames):
        # å„²å­˜åŸå§‹å¹€
        #frame_path = os.path.join(shot_dir, f"frame_{idx:02d}_{int(ts*1000)}.jpg")
        #cv2.imwrite(frame_path, frame)
        
        results = yolo_detect(frame)
        cand = select_best_hit_candidate(frame, results)
        if cand is None:
            continue

        # ä¾‹ï¼šç”¨ green_area ç•¶æ’åºä¾æ“šï¼ˆä½ ä¹Ÿå¯ä»¥åŠ ä¸Šç¶ é»é¢ç©ã€è·é›¢ç­‰ï¼‰
        score = cand["green_area"]
        if (best is None) or (score > best["green_area"]):
            best = cand
            best_ts = ts
            best_frame_idx = idx

    # å¦‚æœæœ‰æœ€ä½³å¹€ï¼Œé¡å¤–æ¨™è¨˜å®ƒ
    if best_frame_idx is not None:
        best_marker_path = os.path.join(shot_dir, f"BEST_frame_{best_frame_idx:02d}.txt")
        with open(best_marker_path, "w") as f:
            f.write(f"Best frame index: {best_frame_idx}\n")
            f.write(f"Timestamp: {best_ts}\n")
            f.write(f"Green area: {best['green_area']}\n")

    return best, best_ts

# ====== é¡¯ç¤ºåŸ·è¡Œç·’ï¼šå³æ™‚é¡¯ç¤ºåµæ¸¬çµæœ ======
def display_loop():
    global stop_flag
    while not stop_flag:
        if len(frame_buffer) == 0:
            time.sleep(0.01)
            continue
        
        # å–æœ€æ–°çš„å¹€
        ts, frame = frame_buffer[-1]
        display_frame = frame.copy()
        
        # åŸ·è¡ŒYOLOåµæ¸¬
        results = yolo_detect(display_frame)
        
        # ç¹ªè£½æ‰€æœ‰åµæ¸¬æ¡†å’Œç¶ é»
        for r in results:
            for box in r.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                conf = float(box.conf[0])
                cls = int(box.cls[0])
                
                if conf < CONF_THRES:
                    continue
                
                # ç¹ªè£½bounding box
                color = (0, 255, 0) if conf >= CONF_THRES else (0, 165, 255)
                cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)
                
                # æ¨™è¨»ä¿¡å¿ƒåº¦
                label = f"Target {conf:.2f}"
                cv2.putText(display_frame, label, (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
                # ç¹ªè£½5å±¤åŒå¿ƒé•·æ–¹å½¢ (è¨ˆåˆ†å€åŸŸ)
                target_cx = (x1 + x2) / 2.0
                target_cy = (y1 + y2) / 2.0
                target_width = x2 - x1
                target_height = y2 - y1
                
                # 5å±¤æ©¢åœ“: 0.1, 0.2, 0.3, 0.4, 0.5
                # é¡è‰²: ç´…->æ©™->é»ƒ->æ·ºè—->æ·±è—
                zone_colors = [
                    (0, 0, 255),      # 10åˆ†: ç´…è‰²
                    (0, 165, 255),    # 9åˆ†: æ©™è‰²
                    (0, 255, 255),    # 8åˆ†: é»ƒè‰²
                    (255, 255, 0),    # 7åˆ†: é’è‰²
                    (255, 0, 0)       # 6åˆ†: è—è‰²
                ]
                zone_ratios = [0.1, 0.2, 0.3, 0.4, 0.5]
                
                for i, ratio in enumerate(zone_ratios):
                    # è¨ˆç®—æ­¤å±¤æ©¢åœ“çš„åŠè»¸é•·åº¦
                    axes_w = int(target_width * ratio)
                    axes_h = int(target_height * ratio)
                    
                    # ç¹ªè£½æ©¢åœ“
                    cv2.ellipse(display_frame, 
                               (int(target_cx), int(target_cy)),  # ä¸­å¿ƒé»
                               (axes_w, axes_h),                   # åŠè»¸é•·åº¦ (å¯¬, é«˜)
                               0,                                   # æ—‹è½‰è§’åº¦
                               0, 360,                             # èµ·å§‹å’ŒçµæŸè§’åº¦
                               zone_colors[i], 1)                  # é¡è‰²å’Œç·šå¯¬
                
                # ç¹ªè£½ä¸­å¿ƒåå­—
                cross_size = 5
                cv2.line(display_frame, 
                        (int(target_cx - cross_size), int(target_cy)),
                        (int(target_cx + cross_size), int(target_cy)),
                        (0, 0, 255), 2)
                cv2.line(display_frame, 
                        (int(target_cx), int(target_cy - cross_size)),
                        (int(target_cx), int(target_cy + cross_size)),
                        (0, 0, 255), 2)
                
                # åœ¨ROIå…§åµæ¸¬ç¶ é»
                h_img, w_img = display_frame.shape[:2]
                x1_c = max(0, x1); y1_c = max(0, y1)
                x2_c = min(w_img, x2); y2_c = min(h_img, y2)
                
                if x2_c > x1_c and y2_c > y1_c:
                    roi = frame[y1_c:y2_c, x1_c:x2_c]
                    if roi.size > 0:
                        point_boxes = detect_point_in_roi(roi, x1_c, y1_c)
                        
                        # ç¹ªè£½ç¶ é»
                        for px, py, pw, ph in point_boxes:
                            cv2.rectangle(display_frame, (px, py), (px+pw, py+ph), (0, 255, 255), 2)
                            # ç¶ é»ä¸­å¿ƒ
                            # cx, cy = bbox_center_xywh(px, py, pw, ph)
                            # cv2.circle(display_frame, (int(cx), int(cy)), 3, (0, 0, 255), -1)
        
        # é¡¯ç¤ºç•«é¢
        cv2.imshow("Detection", display_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            stop_flag = True
            break
    
    cv2.destroyAllWindows()

# ====== ç›¸æ©Ÿæ“·å–åŸ·è¡Œç·’ï¼šåªè² è²¬buffer ======
def camera_loop(cam_id=0):
    global stop_flag
    cap = cv2.VideoCapture(cam_id)
    if not cap.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ")
        stop_flag = True
        return

    while not stop_flag:
        ret, frame = cap.read()
        if not ret:
            continue
        ts = time.time()
        frame_buffer.append((ts, frame))

    cap.release()

# ====== ç¡¬é«”è§¸ç™¼åŸ·è¡Œç·’ï¼šé€é pyserial è®€å– ESP32 æŒ‰éˆ•è¨Šæ¯ ======
def trigger_loop_keyboard():
    global stop_flag
    # è¨­å®š ESP32 çš„ä¸²å£ï¼ˆè«‹æ ¹æ“šå¯¦éš›æƒ…æ³ä¿®æ”¹ COM port å’Œ baudrateï¼‰
    try:
        ports = serial.tools.list_ports.comports()
        for port in ports:
            # Most ESP32 boards contain these strings in their description
            if "CP210" in port.description or "CH340" in port.description or "USB Serial" in port.description:
                print(port.device)
            print(port.description)
        ser = serial.Serial('COM8', 115200, timeout=1)  # ä¿®æ”¹ COM3 ç‚ºä½ çš„ ESP32 ç«¯å£
        print(f"å·²é€£æ¥åˆ° ESP32: {ser.port}")


    except Exception as e:
        print(f"ç„¡æ³•é€£æ¥åˆ° ESP32: {e}")
        return
    
    while not stop_flag:
        try:
            if ser.in_waiting > 0:
                line = ser.readline().decode('utf-8').strip()  # è®€å–ä¸€è¡Œè¨Šæ¯
                if line:  # å¦‚æœæ¥æ”¶åˆ°è¨Šæ¯ï¼ˆä¾‹å¦‚ ESP32 ç™¼é€ "FIRE" æˆ–ä»»ä½•è¨Šæ¯ï¼‰
                    print(f"æ”¶åˆ° ESP32 è¨Šæ¯: {line}")
                    fire_events.put(time.time())
        except Exception as e:
            print(f"è®€å– ESP32 è³‡æ–™éŒ¯èª¤: {e}")
            break
    
    ser.close()
    print("å·²é—œé–‰ ESP32 é€£æ¥")

# ====== äº‹ä»¶è™•ç†ï¼šä¸€æ”¶åˆ°fireå°±æŠ“å¹€ä¸¦åµæ¸¬ï¼Œè¼¸å‡ºJSON ======
def fire_handler_loop():
    shot_idx = 0
    while not stop_flag and shot_idx < MAX_SHOTS:
        fire_ts = fire_events.get()  # block ç­‰å¾…

        # ç­‰å¾…ä¸€é»æ™‚é–“ï¼Œè®“ POST_FRAMES å¹€é€²bufferï¼ˆè·ŸFPSæœ‰é—œï¼‰
        time.sleep(POST_WAIT_SEC)

        # æŠŠ buffer è¤‡è£½å‡ºä¾†é¿å…è¢«åŒæ™‚ä¿®æ”¹
        buf = list(frame_buffer)

        # æ‰¾åˆ° fire_ts åœ¨ buffer ä¸­çš„ä½ç½®ï¼ˆä»¥ timestamp åˆ‡ï¼‰
        # å– fire_ts å‰å¾Œå¹€
        # ä½œæ³•ï¼šæ‰¾æœ€å¾Œä¸€å€‹ ts <= fire_ts çš„ index
        idx = None
        for i in range(len(buf)-1, -1, -1):
            if buf[i][0] <= fire_ts:
                idx = i
                break
        if idx is None:
            idx = 0

        start = max(0, idx - PRE_FRAMES)
        end = min(len(buf), idx + 1 + POST_FRAMES)
        window = buf[start:end]

        best, best_ts = detect_from_frames(window, shot_idx + 1)

        shot_idx += 1
        ts_now = time.time()

        if best is not None:
            payload = {
                "shot_idx": shot_idx,
                # "remain": MAX_SHOTS - shot_idx,
                # "timestamp": ts_now,
                # "fire_ts": fire_ts,
                # "used_frame_ts": best_ts,
                "hit": True,
                "target": {
                    "No": int(best["No"]),
                    "x": float(best["dx"]),
                    "y": float(best["dy"]),
                    "score": int(best["score"])  # ç’°ç‹€è¨ˆåˆ†: 10, 9, 8, 7, 6
                }

            }
        else:
            payload = {
                "shot_idx": shot_idx,
                # "remain": MAX_SHOTS - shot_idx,
                # "timestamp": ts_now,
                # "fire_ts": fire_ts,
                "hit": False,
                # "reason": "no_green_point_in_any_target_box"
            }

        fname = f"{USER_ID}_shot{shot_idx:02d}_{int(ts_now*1000)}.json"
        out_path = os.path.join(SAVE_DIR, fname)
        atomic_write_json(out_path, payload)
        print(f"âœ… å¯«å…¥ {out_path}  hit={payload['hit']}")

    print("ğŸ”š äº”ç™¼çµæŸ / handleråœæ­¢")

# ====== ä¸»ç¨‹å¼ ======
if __name__ == "__main__":
    t_cam = threading.Thread(target=camera_loop, daemon=True)
    t_dsp = threading.Thread(target=display_loop, daemon=True)  # é¡¯ç¤ºåŸ·è¡Œç·’
    t_trg = threading.Thread(target=trigger_loop_keyboard, daemon=True)  # ä¹‹å¾Œæ›æˆç¡¬é«”è¨Šè™Ÿ
    t_hnd = threading.Thread(target=fire_handler_loop, daemon=True)

    t_cam.start()
    t_dsp.start()
    t_trg.start()
    t_hnd.start()

    try:
        while t_hnd.is_alive():
            time.sleep(0.2)
    except KeyboardInterrupt:
        pass

    stop_flag = True
    print("ç¨‹å¼çµæŸ")
